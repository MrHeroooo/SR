{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecognitionNew.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSAPjoK4-Omc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd drive/My\\ Drive/XLTN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBrxtWLJAZtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr-kCUlP-iSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "from sklearn.cluster import KMeans\n",
        "import hmmlearn.hmm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL-U3QMF-scI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_7kr4fh-yxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install hmmlearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya2I1RVS-0V_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mfcc(file_path):\n",
        "    y, sr = librosa.load(file_path) # read .wav file\n",
        "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
        "    win_length = math.floor(sr*0.025) # 25ms frame\n",
        "    # mfcc is 12 x T matrix\n",
        "    mfcc = librosa.feature.mfcc(\n",
        "        y, sr, n_mfcc=12, n_fft=1024,\n",
        "        hop_length=hop_length)\n",
        "        #hop_length=hop_length, win_length=win_length)\n",
        "    # substract mean from mfcc --> normalize mfcc\n",
        "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
        "    # delta feature 1st order and 2nd order\n",
        "    delta1 = librosa.feature.delta(mfcc, order=1)\n",
        "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
        "    # X is 36 x T\n",
        "    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
        "    # return T x 36 (transpose of X)\n",
        "    return X.T # hmmlearn use T x N matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQOVsyJZ-6p3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_class_data(data_dir):\n",
        "    files = os.listdir(data_dir)\n",
        "    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
        "    return mfcc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42Jmjsli-9bH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clustering(X, n_clusters=5):\n",
        "    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
        "    kmeans.fit(X)\n",
        "    print(\"centers\", kmeans.cluster_centers_.shape)\n",
        "    return kmeans  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISVBg1nc_DY-",
        "colab_type": "code",
        "outputId": "bfd1ef25-aa4d-4d2f-87ed-996df3f16a2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "dataset = {}\n",
        "cname =\"co_the\"\n",
        "print(f\"Load {cname} dataset\")\n",
        "dataset[cname] = get_class_data(os.path.join(\"./BT2/\", cname))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load co_the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFFDVPd5_bA-",
        "colab_type": "code",
        "outputId": "34634da4-01b5-463f-b074-627501ca45ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "\n",
        "# Get all vectors in the datasets\n",
        "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
        "print(\"vectors\", all_vectors.shape)\n",
        "# Run K-Means algorithm to get clusters\n",
        "kmeans = clustering(all_vectors)\n",
        "print(\"centers\", kmeans.cluster_centers_.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vectors (3273, 36)\n",
            "centers (5, 36)\n",
            "centers (5, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn9MushJ_rlF",
        "colab_type": "code",
        "outputId": "9c7dee6a-5483-48cb-bc62-9bd0efdbe9b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "class_vectors = dataset[cname]\n",
        "\n",
        "dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
        "random.shuffle(dataset[cname])\n",
        "hmm = hmmlearn.hmm.MultinomialHMM(\n",
        "    n_components=13, random_state=0, n_iter=1000, verbose=True,\n",
        "    startprob_prior=np.array([0.02, 0.58 ,0.23, 0.  , 0.  , 0.17 ,0. ,  0.,   0.,   0.  , 0. ,  0. ,  0.  ]),\n",
        "    transmat_prior=np.array([[0.66 ,0. ,  0.,   0. ,  0. ,  0.,   0. ,  0.34, 0. ,  0. ,  0. ,  0.   ,0.  ],\n",
        " [0.  , 0.57 ,0. ,  0.  , 0. ,  0.23, 0.,   0. ,  0.12 ,0. ,  0.07, 0.  , 0.02],\n",
        " [0.  , 0.31, 0.69, 0. ,  0.,   0. ,  0. ,  0.,   0. ,  0. ,  0. ,  0. ,  0.  ],\n",
        " [0. ,  0. ,  0.  , 0.82, 0.18, 0. ,  0.  , 0.  , 0. ,  0.,   0. ,  0. ,  0.  ],\n",
        " [0.  , 0. ,  0.  , 0.,   0.75, 0. ,  0.24, 0. ,  0.01, 0. , 0.  , 0. ,  0.  ],\n",
        " [0.  , 0.13 ,0. ,  0.  , 0.  , 0.67, 0. ,  0.04 ,0.04 ,0.  , 0.  , 0. ,  0.11],\n",
        " [0.  , 0. ,  0.  , 0. ,  0.07, 0.  , 0.78 ,0. ,  0. ,  0.15, 0. ,  0. ,  0.  ],\n",
        " [0.  , 0. ,  0. ,  0.,   0.  , 0.02, 0.02, 0.07, 0.05, 0.  , 0.84, 0. ,  0.  ],\n",
        " [0.  , 0.,   0.,   0.13 ,0. ,  0.  , 0.14, 0. ,  0.7,  0. ,  0. ,  0.03, 0.  ],\n",
        " [0.  , 0.  , 0.  , 0.,   0. ,  0.  , 0.  , 0.22 ,0.   ,0.78, 0. ,  0. ,  0.  ],\n",
        " [0.  , 0.02, 0.08, 0. ,  0.  , 0.  , 0. ,  0.,   0.17 ,0.  , 0.73, 0. ,  0.  ],\n",
        " [0.  , 0.  , 0. ,  0.  , 0. ,  0.  , 0.43, 0.  , 0. ,  0. ,  0.  , 0.57 ,0.  ],\n",
        " [0.  , 0.,   0.  , 0. ,  0. ,  0.22, 0. ,  0. ,  0.  , 0.   ,0.  , 0.  , 0.78]])\n",
        ")\n",
        "\n",
        "X = np.concatenate(dataset[cname])\n",
        "lengths = list([len(x) for x in dataset[cname]])\n",
        "print(\"training class\", cname)\n",
        "print(X.shape, lengths, len(lengths))\n",
        "hmm.fit(X, lengths=lengths)\n",
        "\n",
        "with open(\"co_the_model.pkl\", \"wb\") as file: pickle.dump(hmm, file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training class co_the\n",
            "(3273, 1) [52, 19, 25, 32, 30, 22, 25, 53, 30, 52, 32, 36, 36, 24, 23, 36, 32, 33, 27, 27, 27, 28, 44, 27, 35, 22, 27, 27, 30, 27, 24, 50, 25, 30, 24, 30, 29, 37, 46, 24, 21, 50, 34, 32, 41, 34, 34, 85, 26, 26, 52, 41, 37, 32, 25, 26, 57, 21, 23, 34, 19, 24, 25, 24, 35, 33, 20, 36, 19, 38, 31, 44, 28, 30, 29, 16, 24, 36, 34, 35, 22, 37, 30, 25, 41, 32, 22, 23, 20, 21, 34, 24, 27, 36, 19, 36, 32, 47, 20, 53, 41, 29, 32] 103\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "         1       -5181.7019             +nan\n",
            "         2       -5017.5278        +164.1741\n",
            "         3       -4928.6408         +88.8870\n",
            "         4       -4721.2866        +207.3542\n",
            "         5       -4246.5101        +474.7765\n",
            "         6       -3449.3520        +797.1581\n",
            "         7       -2892.5886        +556.7634\n",
            "         8       -2768.0510        +124.5376\n",
            "         9       -2712.1538         +55.8972\n",
            "        10       -2652.2685         +59.8853\n",
            "        11       -2572.0744         +80.1941\n",
            "        12       -2480.5307         +91.5437\n",
            "        13       -2404.4506         +76.0801\n",
            "        14       -2358.9274         +45.5232\n",
            "        15       -2324.1538         +34.7737\n",
            "        16       -2283.8335         +40.3203\n",
            "        17       -2246.4553         +37.3782\n",
            "        18       -2215.1197         +31.3357\n",
            "        19       -2192.4895         +22.6301\n",
            "        20       -2177.4694         +15.0201\n",
            "        21       -2166.8299         +10.6395\n",
            "        22       -2157.7791          +9.0507\n",
            "        23       -2149.5168          +8.2623\n",
            "        24       -2141.1827          +8.3342\n",
            "        25       -2132.7628          +8.4199\n",
            "        26       -2125.9436          +6.8191\n",
            "        27       -2122.7723          +3.1714\n",
            "        28       -2121.1061          +1.6662\n",
            "        29       -2118.8877          +2.2184\n",
            "        30       -2117.6353          +1.2524\n",
            "        31       -2116.2785          +1.3568\n",
            "        32       -2116.6117          -0.3332\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqCAt9VaDN7S",
        "colab_type": "code",
        "outputId": "dc5546d1-e923-4d7b-a2df-a226d7ed6132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        }
      },
      "source": [
        "dataset = {}\n",
        "cname =\"khong\"\n",
        "print(f\"Load {cname} dataset\")\n",
        "dataset[cname] = get_class_data(os.path.join(\"./BT2/\", cname))\n",
        "\n",
        "# Get all vectors in the datasets\n",
        "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
        "print(\"vectors\", all_vectors.shape)\n",
        "# Run K-Means algorithm to get clusters\n",
        "kmeans = clustering(all_vectors)\n",
        "print(\"centers\", kmeans.cluster_centers_.shape)\n",
        "\n",
        "class_vectors = dataset[cname]\n",
        "\n",
        "dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
        "random.shuffle(dataset[cname])\n",
        "hmm = hmmlearn.hmm.MultinomialHMM(\n",
        "    n_components=9, random_state=0, n_iter=1000, verbose=True,\n",
        "    startprob_prior=np.array([0.02, 0.45 ,0. ,  0.07, 0.26 ,0.07 ,0.13, 0.  , 0.  ]),\n",
        "    transmat_prior=np.array([[0.4 ,0.  ,0.,  0. , 0. , 0.5, 0. , 0.  ,0. ],\n",
        " [0. , 0.6 ,0. , 0. , 0.,  0. , 0.,  0.3, 0. ],\n",
        " [0. , 0.4, 0.3, 0.1 ,0.1, 0.,  0. , 0. , 0. ],\n",
        " [0. , 0. , 0. , 0.8, 0. , 0. , 0.,  0.,  0.1],\n",
        " [0. , 0. , 0.1, 0.,  0.8, 0.,  0.,  0. , 0. ],\n",
        " [0. , 0.,  0. , 0.2, 0. , 0.3, 0.,  0. , 0.4],\n",
        " [0. , 0. , 0.,  0.,  0.1, 0.,  0.9, 0.,  0. ],\n",
        " [0.1 ,0. , 0. , 0.1 ,0. , 0.2, 0. , 0.6, 0. ],\n",
        " [0.  ,0. , 0. , 0. , 0.  ,0. , 0.2, 0. , 0.8]])\n",
        ")\n",
        "\n",
        "X = np.concatenate(dataset[cname])\n",
        "lengths = list([len(x) for x in dataset[cname]])\n",
        "print(\"training class\", cname)\n",
        "print(X.shape, lengths, len(lengths))\n",
        "hmm.fit(X, lengths=lengths)\n",
        "with open(\"khong_model.pkl\", \"wb\") as file: pickle.dump(hmm, file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load khong dataset\n",
            "vectors (3146, 36)\n",
            "centers (5, 36)\n",
            "centers (5, 36)\n",
            "training class khong\n",
            "(3146, 1) [30, 31, 18, 24, 27, 26, 33, 23, 19, 29, 31, 12, 26, 23, 25, 21, 23, 22, 33, 29, 23, 23, 20, 26, 19, 27, 18, 27, 25, 29, 20, 654, 22, 38, 28, 22, 22, 40, 26, 19, 45, 30, 29, 21, 27, 14, 28, 27, 25, 25, 23, 19, 28, 32, 27, 16, 29, 22, 22, 16, 27, 14, 27, 33, 23, 19, 28, 25, 21, 20, 25, 21, 18, 30, 26, 42, 23, 28, 37, 28, 18, 17, 23, 34, 19, 24, 24, 28, 19, 14, 24, 24, 32, 30, 32, 23, 24, 27, 29, 28] 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "         1       -5078.2901             +nan\n",
            "         2       -4859.9989        +218.2911\n",
            "         3       -4743.1976        +116.8013\n",
            "         4       -4493.2868        +249.9108\n",
            "         5       -4124.7024        +368.5844\n",
            "         6       -3759.9478        +364.7546\n",
            "         7       -3260.3314        +499.6165\n",
            "         8       -2658.8954        +601.4359\n",
            "         9       -2353.7909        +305.1046\n",
            "        10       -2246.7569        +107.0340\n",
            "        11       -2199.8660         +46.8908\n",
            "        12       -2172.4785         +27.3875\n",
            "        13       -2157.6052         +14.8734\n",
            "        14       -2149.7157          +7.8895\n",
            "        15       -2144.2447          +5.4710\n",
            "        16       -2140.2506          +3.9941\n",
            "        17       -2137.1414          +3.1092\n",
            "        18       -2134.5411          +2.6003\n",
            "        19       -2132.4561          +2.0850\n",
            "        20       -2131.0932          +1.3629\n",
            "        21       -2128.4970          +2.5962\n",
            "        22       -2126.5758          +1.9212\n",
            "        23       -2125.1064          +1.4694\n",
            "        24       -2123.8779          +1.2285\n",
            "        25       -2123.0612          +0.8167\n",
            "        26       -2122.6257          +0.4355\n",
            "        27       -2122.3004          +0.3253\n",
            "        28       -2122.0225          +0.2779\n",
            "        29       -2121.7671          +0.2554\n",
            "        30       -2121.5204          +0.2467\n",
            "        31       -2121.2764          +0.2440\n",
            "        32       -2121.0341          +0.2423\n",
            "        33       -2120.7955          +0.2386\n",
            "        34       -2120.5640          +0.2315\n",
            "        35       -2120.3436          +0.2204\n",
            "        36       -2120.1384          +0.2053\n",
            "        37       -2119.9516          +0.1867\n",
            "        38       -2119.7860          +0.1656\n",
            "        39       -2119.6433          +0.1427\n",
            "        40       -2119.5244          +0.1189\n",
            "        41       -2119.4295          +0.0949\n",
            "        42       -2119.4217          +0.0078\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWlxJoNJEIwR",
        "colab_type": "code",
        "outputId": "b145912b-0b6e-4c01-bb0d-1303e5479793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        }
      },
      "source": [
        "dataset = {}\n",
        "cname =\"nay\"\n",
        "print(f\"Load {cname} dataset\")\n",
        "dataset[cname] = get_class_data(os.path.join(\"./BT2/\", cname))\n",
        "\n",
        "# Get all vectors in the datasets\n",
        "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
        "print(\"vectors\", all_vectors.shape)\n",
        "# Run K-Means algorithm to get clusters\n",
        "kmeans = clustering(all_vectors)\n",
        "print(\"centers\", kmeans.cluster_centers_.shape)\n",
        "\n",
        "class_vectors = dataset[cname]\n",
        "\n",
        "dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
        "random.shuffle(dataset[cname])\n",
        "hmm = hmmlearn.hmm.MultinomialHMM(\n",
        "    n_components=9, random_state=0, n_iter=1000, verbose=True,\n",
        "    startprob_prior=np.array([0.2, 0.,  0. , 0.8 ,0. , 0. , 0.,  0. , 0. ]),\n",
        "    transmat_prior=np.array([[0.8 , 0.  , 0. ,  0. ,  0. ,  0. ,  0.2 , 0. ,  0.  ],\n",
        " [0.  , 0. ,  0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
        " [0.  , 0.,   0.74, 0. ,  0. ,  0. ,  0. ,  0.26 ,0.  ],\n",
        " [0.22, 0. ,  0. ,  0.77 ,0. ,  0. ,  0. ,  0. ,  0.02],\n",
        " [0.  , 0.01 ,0.27, 0. ,  0.72, 0.,   0.  , 0.  , 0.  ],\n",
        " [0.  , 0. ,  0.,   0.  , 0.31, 0.69, 0. ,  0.  , 0.  ],\n",
        " [0.  , 0. ,  0.  , 0.   ,0.,   0.,   0.8 , 0. ,  0.2 ],\n",
        " [0.  , 0.  , 0.  , 0.,   0. ,  0. ,  0.,   1. ,  0.  ],\n",
        " [0.  , 0. ,  0.   ,0.,   0.  , 0.32, 0.  , 0.  , 0.68]])\n",
        ")\n",
        "\n",
        "X = np.concatenate(dataset[cname])\n",
        "lengths = list([len(x) for x in dataset[cname]])\n",
        "print(\"training class\", cname)\n",
        "print(X.shape, lengths, len(lengths))\n",
        "hmm.fit(X, lengths=lengths)\n",
        "with open(\"nay_model.pkl\", \"wb\") as file: pickle.dump(hmm, file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load nay dataset\n",
            "vectors (2884, 36)\n",
            "centers (5, 36)\n",
            "centers (5, 36)\n",
            "training class nay\n",
            "(2884, 1) [15, 25, 24, 37, 32, 19, 32, 33, 28, 31, 14, 36, 34, 24, 36, 33, 26, 32, 34, 36, 36, 27, 35, 35, 14, 33, 32, 31, 33, 27, 19, 34, 35, 32, 25, 27, 25, 25, 22, 28, 37, 25, 32, 28, 28, 30, 22, 32, 36, 35, 31, 27, 19, 34, 30, 33, 28, 24, 36, 25, 28, 15, 37, 14, 24, 29, 32, 28, 34, 33, 30, 33, 35, 32, 29, 30, 27, 35, 37, 15, 36, 27, 26, 33, 30, 22, 36, 32, 24, 37, 36, 34, 29, 37, 34, 28, 26, 32] 98\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "         1       -4659.1084             +nan\n",
            "         2       -4379.3834        +279.7250\n",
            "         3       -4255.7172        +123.6662\n",
            "         4       -4022.9410        +232.7762\n",
            "         5       -3720.3273        +302.6137\n",
            "         6       -3235.0778        +485.2495\n",
            "         7       -2421.6140        +813.4637\n",
            "         8       -1829.8193        +591.7947\n",
            "         9       -1684.1874        +145.6319\n",
            "        10       -1650.4357         +33.7517\n",
            "        11       -1610.9259         +39.5098\n",
            "        12       -1476.0490        +134.8770\n",
            "        13       -1281.6545        +194.3944\n",
            "        14       -1198.4038         +83.2508\n",
            "        15       -1174.7351         +23.6686\n",
            "        16       -1163.9887         +10.7465\n",
            "        17       -1155.6797          +8.3090\n",
            "        18       -1147.8752          +7.8044\n",
            "        19       -1140.4913          +7.3839\n",
            "        20       -1133.1109          +7.3803\n",
            "        21       -1125.5908          +7.5201\n",
            "        22       -1118.9107          +6.6802\n",
            "        23       -1115.5621          +3.3485\n",
            "        24       -1113.9358          +1.6263\n",
            "        25       -1112.5270          +1.4089\n",
            "        26       -1111.2756          +1.2514\n",
            "        27       -1110.1615          +1.1141\n",
            "        28       -1109.1698          +0.9918\n",
            "        29       -1108.2922          +0.8776\n",
            "        30       -1107.5845          +0.7077\n",
            "        31       -1106.8646          +0.7199\n",
            "        32       -1105.9582          +0.9064\n",
            "        33       -1104.9636          +0.9946\n",
            "        34       -1103.7728          +1.1908\n",
            "        35       -1102.3256          +1.4471\n",
            "        36       -1100.5556          +1.7701\n",
            "        37       -1098.4095          +2.1461\n",
            "        38       -1095.8777          +2.5318\n",
            "        39       -1093.0375          +2.8402\n",
            "        40       -1090.0878          +2.9498\n",
            "        41       -1087.3211          +2.7667\n",
            "        42       -1085.1724          +2.1487\n",
            "        43       -1084.0030          +1.1694\n",
            "        44       -1083.3474          +0.6556\n",
            "        45       -1083.0151          +0.3323\n",
            "        46       -1082.9339          +0.0812\n",
            "        47       -1082.8880          +0.0460\n",
            "        48       -1082.6813          +0.2066\n",
            "        49       -1082.6253          +0.0561\n",
            "        50       -1082.5929          +0.0324\n",
            "        51       -1082.5742          +0.0187\n",
            "        52       -1082.5635          +0.0107\n",
            "        53       -1082.5573          +0.0062\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYRM0xfTEiS9",
        "colab_type": "code",
        "outputId": "39ee5eeb-9e94-4d06-ca90-a6a1a17978ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dataset = {}\n",
        "cname =\"nguoi\"\n",
        "print(f\"Load {cname} dataset\")\n",
        "dataset[cname] = get_class_data(os.path.join(\"./BT2/\", cname))\n",
        "\n",
        "# Get all vectors in the datasets\n",
        "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
        "print(\"vectors\", all_vectors.shape)\n",
        "# Run K-Means algorithm to get clusters\n",
        "kmeans = clustering(all_vectors)\n",
        "print(\"centers\", kmeans.cluster_centers_.shape)\n",
        "\n",
        "class_vectors = dataset[cname]\n",
        "\n",
        "dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
        "random.shuffle(dataset[cname])\n",
        "hmm = hmmlearn.hmm.MultinomialHMM(\n",
        "    n_components=9, random_state=0, n_iter=1000, verbose=True,\n",
        "    startprob_prior=np.array([0.  , 0.  , 0.  , 0.21 ,0. ,  0. ,  0. ,  0.37, 0.42]),\n",
        "    transmat_prior=np.array([[0.  , 0. ,  0. ,  0. ,  0.,   0. ,  1. ,  0. ,  0.  ],\n",
        " [0.08, 0.64, 0.27, 0.,   0.,   0. ,  0.  , 0. ,  0.  ],\n",
        " [0.  , 0.  , 0.43 ,0. ,  0.57, 0.  , 0. ,  0. ,  0.  ],\n",
        " [0.01, 0.03, 0.  , 0.81, 0. ,  0.16, 0. ,  0. ,  0.  ],\n",
        " [0.  , 0.  , 0.   ,0. ,  0.81 ,0. ,  0.19 ,0. ,  0.  ],\n",
        " [0.  , 0.46, 0.  , 0.  , 0.  , 0.42 ,0.  , 0.12, 0.  ],\n",
        " [0.  , 0.  , 0. ,  0. ,  0. ,  0. ,  0.84 ,0.01, 0.14],\n",
        " [0.  , 0.18 ,0.  , 0.12 ,0.  , 0.13 ,0.  , 0.57, 0.  ],\n",
        " [0.   ,0. ,  0.  , 0.3 , 0. ,  0. ,  0. , 0.   ,0.7 ]])\n",
        ")\n",
        "\n",
        "X = np.concatenate(dataset[cname])\n",
        "lengths = list([len(x) for x in dataset[cname]])\n",
        "print(\"training class\", cname)\n",
        "print(X.shape, lengths, len(lengths))\n",
        "hmm.fit(X, lengths=lengths)\n",
        "with open(\"nguoi_model.pkl\", \"wb\") as file: pickle.dump(hmm, file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load nguoi dataset\n",
            "vectors (2597, 36)\n",
            "centers (5, 36)\n",
            "centers (5, 36)\n",
            "training class nguoi\n",
            "(2597, 1) [25, 33, 36, 20, 31, 18, 47, 18, 55, 19, 28, 15, 22, 20, 19, 30, 40, 23, 23, 20, 22, 22, 17, 18, 15, 21, 18, 44, 38, 29, 23, 22, 32, 35, 24, 20, 24, 22, 18, 53, 23, 34, 19, 23, 18, 22, 20, 44, 15, 20, 24, 35, 17, 37, 22, 26, 30, 25, 27, 16, 21, 26, 37, 22, 29, 23, 30, 17, 16, 33, 30, 36, 39, 13, 20, 25, 30, 22, 16, 18, 30, 17, 21, 20, 16, 25, 19, 33, 22, 48, 16, 16, 23, 22, 36, 19, 28, 14, 18, 36, 39, 20] 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "         1       -4338.5511             +nan\n",
            "         2       -3939.9885        +398.5625\n",
            "         3       -3797.5630        +142.4255\n",
            "         4       -3522.1818        +275.3812\n",
            "         5       -3149.0823        +373.0995\n",
            "         6       -2681.9602        +467.1222\n",
            "         7       -2163.8522        +518.1079\n",
            "         8       -1961.8329        +202.0193\n",
            "         9       -1912.6899         +49.1430\n",
            "        10       -1883.6086         +29.0813\n",
            "        11       -1864.0325         +19.5761\n",
            "        12       -1850.3622         +13.6703\n",
            "        13       -1840.1207         +10.2415\n",
            "        14       -1831.1636          +8.9571\n",
            "        15       -1822.7105          +8.4531\n",
            "        16       -1815.0923          +7.6182\n",
            "        17       -1808.7754          +6.3169\n",
            "        18       -1804.2488          +4.5265\n",
            "        19       -1800.6500          +3.5988\n",
            "        20       -1797.9388          +2.7112\n",
            "        21       -1796.0253          +1.9135\n",
            "        22       -1794.9223          +1.1030\n",
            "        23       -1794.0993          +0.8230\n",
            "        24       -1793.4397          +0.6596\n",
            "        25       -1792.8916          +0.5481\n",
            "        26       -1792.4135          +0.4781\n",
            "        27       -1792.0918          +0.3217\n",
            "        28       -1791.8138          +0.2780\n",
            "        29       -1791.5567          +0.2571\n",
            "        30       -1791.3385          +0.2182\n",
            "        31       -1791.1668          +0.1717\n",
            "        32       -1790.8930          +0.2738\n",
            "        33       -1790.7009          +0.1922\n",
            "        34       -1790.5486          +0.1523\n",
            "        35       -1790.4210          +0.1275\n",
            "        36       -1790.3100          +0.1111\n",
            "        37       -1790.2108          +0.0991\n",
            "        38       -1790.1212          +0.0897\n",
            "        39       -1790.0358          +0.0854\n",
            "        40       -1789.9416          +0.0942\n",
            "        41       -1789.8707          +0.0709\n",
            "        42       -1789.8053          +0.0654\n",
            "        43       -1789.7448          +0.0605\n",
            "        44       -1789.6890          +0.0558\n",
            "        45       -1789.6377          +0.0513\n",
            "        46       -1789.5909          +0.0468\n",
            "        47       -1789.5483          +0.0425\n",
            "        48       -1789.5100          +0.0384\n",
            "        49       -1789.4756          +0.0343\n",
            "        50       -1789.4453          +0.0304\n",
            "        51       -1789.4187          +0.0266\n",
            "        52       -1789.3958          +0.0229\n",
            "        53       -1789.3766          +0.0193\n",
            "        54       -1789.3609          +0.0157\n",
            "        55       -1789.3487          +0.0122\n",
            "        56       -1789.3401          +0.0086\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wG4yqYtE16n",
        "colab_type": "code",
        "outputId": "d7f15f46-7750-4982-aac8-d51b9d068e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dataset = {}\n",
        "cname =\"toi\"\n",
        "print(f\"Load {cname} dataset\")\n",
        "dataset[cname] = get_class_data(os.path.join(\"./BT2/\", cname))\n",
        "\n",
        "# Get all vectors in the datasets\n",
        "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
        "print(\"vectors\", all_vectors.shape)\n",
        "# Run K-Means algorithm to get clusters\n",
        "kmeans = clustering(all_vectors)\n",
        "print(\"centers\", kmeans.cluster_centers_.shape)\n",
        "\n",
        "class_vectors = dataset[cname]\n",
        "\n",
        "dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
        "random.shuffle(dataset[cname])\n",
        "hmm = hmmlearn.hmm.MultinomialHMM(\n",
        "    n_components=9, random_state=0, n_iter=1000, verbose=True,\n",
        "    startprob_prior=np.array([0. ,  0.  , 0. ,  0.01 ,0. ,  0. ,  0. ,  0. ,  0.99]),\n",
        "    transmat_prior=np.array([[1. ,  0.,   0.  , 0.  , 0.  , 0. ,  0. ,  0. ,  0.  ],\n",
        " [0.,   0.62, 0.38, 0. ,  0.  , 0. ,  0. ,  0.  , 0.  ],\n",
        " [0.  , 0.  , 0.55 ,0.  , 0.04, 0. ,  0.41, 0. ,  0.  ],\n",
        " [0.  , 0.34 ,0.  , 0.61 ,0. ,  0.  , 0.,   0.05 ,0.  ],\n",
        " [0.  , 0. ,  0.  , 0.  , 0.69 ,0.  , 0.31 ,0. ,  0.  ],\n",
        " [0.  , 0.  , 0.02, 0.25 ,0. ,  0.73, 0.  , 0.   ,0.  ],\n",
        " [0.15, 0. ,  0.  , 0.  , 0.,   0.,   0.85 ,0. ,  0.  ],\n",
        " [0.  , 0. ,  0.,   0.,   0.,   0. ,  0.32, 0.68 ,0.  ],\n",
        " [0.  , 0. ,  0. ,  0.,   0.,   0.5,  0.,   0. ,  0.5 ]])\n",
        ")\n",
        "\n",
        "X = np.concatenate(dataset[cname])\n",
        "lengths = list([len(x) for x in dataset[cname]])\n",
        "print(\"training class\", cname)\n",
        "print(X.shape, lengths, len(lengths))\n",
        "hmm.fit(X, lengths=lengths)\n",
        "with open(\"toi_model.pkl\", \"wb\") as file: pickle.dump(hmm, file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load toi dataset\n",
            "vectors (1701, 36)\n",
            "centers (5, 36)\n",
            "centers (5, 36)\n",
            "training class toi\n",
            "(1701, 1) [13, 13, 12, 16, 13, 22, 16, 17, 21, 13, 13, 19, 17, 16, 16, 16, 18, 17, 18, 10, 29, 18, 23, 12, 11, 17, 26, 21, 14, 12, 21, 18, 17, 17, 12, 24, 23, 10, 15, 26, 28, 26, 19, 16, 20, 31, 18, 18, 24, 14, 17, 12, 16, 10, 23, 16, 19, 19, 17, 14, 20, 16, 12, 14, 9, 14, 13, 14, 15, 13, 24, 14, 18, 17, 11, 15, 13, 16, 18, 17, 12, 21, 21, 10, 25, 16, 16, 19, 18, 18, 14, 22, 23, 22, 26, 16, 13, 16, 11] 99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "         1       -2710.3285             +nan\n",
            "         2       -2354.4803        +355.8483\n",
            "         3       -2309.9312         +44.5491\n",
            "         4       -2226.4407         +83.4905\n",
            "         5       -2061.5256        +164.9151\n",
            "         6       -1799.5045        +262.0211\n",
            "         7       -1475.7581        +323.7464\n",
            "         8       -1262.9272        +212.8308\n",
            "         9       -1181.2228         +81.7044\n",
            "        10       -1137.8456         +43.3772\n",
            "        11       -1111.2389         +26.6068\n",
            "        12       -1092.7198         +18.5190\n",
            "        13       -1083.4307          +9.2892\n",
            "        14       -1075.0782          +8.3524\n",
            "        15       -1068.6312          +6.4470\n",
            "        16       -1063.8604          +4.7709\n",
            "        17       -1059.7570          +4.1034\n",
            "        18       -1056.6402          +3.1168\n",
            "        19       -1054.2382          +2.4020\n",
            "        20       -1052.3374          +1.9009\n",
            "        21       -1050.7914          +1.5459\n",
            "        22       -1049.4454          +1.3460\n",
            "        23       -1048.1496          +1.2958\n",
            "        24       -1047.0666          +1.0830\n",
            "        25       -1045.8897          +1.1769\n",
            "        26       -1044.9476          +0.9421\n",
            "        27       -1044.1304          +0.8172\n",
            "        28       -1043.4115          +0.7189\n",
            "        29       -1042.7756          +0.6359\n",
            "        30       -1042.3958          +0.3798\n",
            "        31       -1042.0421          +0.3538\n",
            "        32       -1041.7217          +0.3204\n",
            "        33       -1041.4795          +0.2422\n",
            "        34       -1041.2343          +0.2452\n",
            "        35       -1040.9973          +0.2370\n",
            "        36       -1040.7343          +0.2629\n",
            "        37       -1040.4920          +0.2424\n",
            "        38       -1040.2299          +0.2621\n",
            "        39       -1039.9366          +0.2933\n",
            "        40       -1039.5447          +0.3919\n",
            "        41       -1039.2073          +0.3374\n",
            "        42       -1038.9107          +0.2966\n",
            "        43       -1038.6680          +0.2427\n",
            "        44       -1038.4756          +0.1924\n",
            "        45       -1038.3256          +0.1500\n",
            "        46       -1038.2100          +0.1156\n",
            "        47       -1038.1218          +0.0883\n",
            "        48       -1038.0548          +0.0669\n",
            "        49       -1038.0044          +0.0504\n",
            "        50       -1037.9667          +0.0377\n",
            "        51       -1037.9389          +0.0279\n",
            "        52       -1037.9186          +0.0203\n",
            "        53       -1037.9041          +0.0145\n",
            "        54       -1037.8942          +0.0099\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B9dEDRyGV1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names_test = [\"test\"]\n",
        "test_dataset = {}\n",
        "for cname in class_names_test:\n",
        "    print(f\"Load {cname} dataset\")\n",
        "    test_dataset[cname] = get_class_data(os.path.join(\"./BT2/\", cname))\n",
        "\n",
        "# Get all vectors in the datasets\n",
        "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in test_dataset.items()], axis=0)\n",
        "print(\"vectors\", all_vectors.shape)\n",
        "# Run K-Means algorithm to get clusters\n",
        "kmeans = clustering(all_vectors)\n",
        "print(\"centers\", kmeans.cluster_centers_.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg5Qxin2RYnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models={}\n",
        "\n",
        "\n",
        "cname = \"co_the\"\n",
        "pkl_filename = 'co_the_model6.pkl'\n",
        "# Loading the saved model pickle\n",
        "model_pkl = open(pkl_filename, 'rb')\n",
        "model = pickle.load(model_pkl)\n",
        "models[cname] = model\n",
        "\n",
        "cname = \"khong\"\n",
        "pkl_filename = 'khong_model6.pkl'\n",
        "# Loading the saved model pickle\n",
        "model_pkl = open(pkl_filename, 'rb')\n",
        "model = pickle.load(model_pkl)\n",
        "models[cname] = model\n",
        "\n",
        "cname = \"nguoi\"\n",
        "pkl_filename = 'nguoi_model6.pkl'\n",
        "# Loading the saved model pickle\n",
        "model_pkl = open(pkl_filename, 'rb')\n",
        "model = pickle.load(model_pkl)\n",
        "models[cname] = model\n",
        "\n",
        "cname = \"toi\"\n",
        "pkl_filename = 'toi_model6.pkl'\n",
        "# Loading the saved model pickle\n",
        "model_pkl = open(pkl_filename, 'rb')\n",
        "model = pickle.load(model_pkl)\n",
        "models[cname] = model\n",
        "\n",
        "cname = \"nay\"\n",
        "pkl_filename = 'nay_model6.pkl'\n",
        "# Loading the saved model pickle\n",
        "model_pkl = open(pkl_filename, 'rb')\n",
        "model = pickle.load(model_pkl)\n",
        "models[cname] = model\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30ANV5szSHUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = [\"test\"]\n",
        "dataset = {}\n",
        "for cname in class_names:\n",
        "    dataset[cname] = get_class_data(os.path.join(\"./BT2/\", cname))\n",
        "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
        "#kmeans = clustering(all_vectors)\n",
        "\n",
        "for cname in class_names:\n",
        "    class_vectors = dataset[cname]\n",
        "    dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
        "    X = np.concatenate(dataset[cname])\n",
        "    lengths = list([len(x) for x in dataset[cname]])\n",
        "\n",
        "for true_cname in class_names:\n",
        "\n",
        "    for O in dataset[true_cname]:\n",
        "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
        "        max_value = max(score.values())\n",
        "        max_key =[k for k, v in score.items() if v == max_value]\n",
        "        max_key = str(max_key)\n",
        "        max_key = max_key.split(\"'\")[1]\n",
        "        print(max_key)   # in ra xem nó là class nào\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGni5L3US8vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load all train data to count acc\n",
        "class_names = [\"co_the\", \"khong\", \"nay\", \"nguoi\", \"toi\", \"test\"]\n",
        "dataset = {}\n",
        "for cname in class_names:\n",
        "    print(f\"Load {cname} dataset\")\n",
        "    dataset[cname] = get_class_data(os.path.join(\"./BT2/\", cname))\n",
        "\n",
        "# Get all vectors in the datasets\n",
        "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
        "print(\"vectors\", all_vectors.shape)\n",
        "# Run K-Means algorithm to get clusters\n",
        "kmeans = clustering(all_vectors)\n",
        "print(\"centers\", kmeans.cluster_centers_.shape)\n",
        "\n",
        "\n",
        "for cname in class_names:\n",
        "    class_vectors = dataset[cname]\n",
        "    # convert all vectors to the cluster index\n",
        "    # dataset['one'] = [O^1, ... O^R]\n",
        "    # O^r = (c1, c2, ... ct, ... cT)\n",
        "    # O^r size T x 1\n",
        "    dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
        "    \n",
        "    if cname[:4] != 'test':\n",
        "        X = np.concatenate(dataset[cname])\n",
        "        lengths = list([len(x) for x in dataset[cname]])\n",
        "        print(\"training class\", cname)\n",
        "        print(X.shape, lengths, len(lengths))\n",
        "        \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VraiwbwvR-25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = [\"co_the\", \"khong\", \"nay\", \"nguoi\", \"toi\"]\n",
        "print(\"Testing\")  \n",
        "\n",
        "for true_cname in class_names:\n",
        "    correct = 0\n",
        "    alll = 0    \n",
        "    alll = alll +1\n",
        "    for O in dataset[true_cname]:\n",
        "        alll = alll +1\n",
        "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
        "        max_value = max(score.values())\n",
        "\n",
        "        max_key =[k for k, v in score.items() if v == max_value]\n",
        "        max_key = str(max_key)\n",
        "        max_key = max_key.split(\"'\")[1]\n",
        "        if max_key == true_cname:\n",
        "          correct = correct +1\n",
        "        print(true_cname, score)\n",
        "    accuracy = correct/alll\n",
        "    print(\"Accuracy \"  + str(accuracy) + \"%\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx5ffn0bToFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = [\"co_the\", \"khong\", \"nay\", \"nguoi\", \"toi\"]\n",
        "print(\"Testing\")  \n",
        "correct = 0\n",
        "alll = 0\n",
        "for true_cname in class_names:\n",
        "    alll = alll +1\n",
        "    for O in dataset[true_cname]:\n",
        "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
        "        max_value = max(score.values())\n",
        "\n",
        "        max_key =[k for k, v in score.items() if v == max_value]\n",
        "        max_key = str(max_key)\n",
        "        max_key = max_key.split(\"'\")[1]\n",
        "        if max_key == true_cname:\n",
        "          correct = correct +1\n",
        "        print(true_cname, score)\n",
        "accuracy = correct/alll\n",
        "print(\"Accuracy = \" + str(accuracy) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}